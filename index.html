<html>
<head>
<title>Veter - robot for researchers</title>
</head>
<body>

<font face="arial">

<center>
<img src="vlogo2.png"><br>
<font face="arial" size="4" color="0e4d6c">
<b>Veter - robotics vehicle for researchers and makers</b>
</font>
</center>

<center>

<br/>
<br/>

<style type="text/css">
table.menu {
  font-family: arial;
  font-weight: bold;
  color: white;
  border-width: 1px;
  border-spacing: 2px;
  border-style: solid;
  border-color: #0e4d6c;
  border-collapse: collapse;
  background-color: #0e4d6c);
}
table.menu td {
  border-width: 1px;
  padding: 4px;
  border-style: inset;
  border-color: light-gray;
  background-color: #0e4d6c;
}
</style>

<table class="menu">
<tr>
  <td>BUILD YOURSELF</td>
  <td>ORDER KIT</td>
  <td>PARTICIPATE AND CONTRIBUTE</td>
  <td>PROJECT BLOG</td>
  <td>ABOUT US</td>
</tr>
</table>

</center>

<div align="justify" style="width: 95%; margin: 0 auto;">
<p>
The main goal of the Veter-project is to build software and hardware infrastructure for the vehicles controlled over the Internet. One of the most important requirements we defined for ourselves was to reduce the amount of required hardware components. We believe that such approach will considerably simplify the hardware building step and as a result can attract more hobby makers. In addition, such approach leads to more compact hardware design. Current hardware design is built around popular BeagleBoard open hardware platform.
</p>
<p>
At the software side, we are using modern libraries and building blocks such as Gstreamer, Ice, Angstrom Linux distribution and many others to leverage the proved solutions and only program what is not available yet.
</p>
<p>
What we have made so far is very powerful platform to experiment with computer vision and artificial intelligence algorithms. Powerful on-board OMAP3530 processor makes it possible to implement complex navigation algorithms. In addition, extremely complex navigation, image processing and analysis algorithms could be implemented on the "driver" side. Our software infrastructure delivers all sensor data (including live video stream) to the driver console where the power of GP GPU or calculation cluster based solutions could be leveraged to reach unprecedented level of intelligent robot behavior. Just as one possible direction, we would like to mention that we are currently working on integrating Amazon's GPU enriched EC2 clusters into our software infrastructure to solve navigation problems in real-time at the not yet seen level of performance and complexity.
</p>

</div>

</font>

</body>
</html>
